title: "Detecting Persuasion with spaCy"
description: "Configuration and code accompanying
_[Detecting Persuasion with spaCy](https://cees-roele.medium.com/detecting-persuasion-with-spacy-6b6beba51076)_.\n

_Persuasion techniques_ express shortcuts in the argumentation process,
e.g. by leveraging on the _emotions_ of the audience or by using _logical fallacies_ to influence it.
This project creates a spaCy pipeline with a `SpanCategorizer` to detect and
classify spans in which persuasion techniques are used in a text.\n
\n
Notes:\n
* No other pre-processing of data is performed except conversion to `spacy` binary format.\n
* Default configuration files are used for _small_, _large_, and _transformer_ models.\n
* After training/evaluation of every model, **the created model is removed**!
For the purpose of the associated article, we are interested in the metrics, not the created models.\n
* For the article describing this project, `suggester` configuration is changed manually to
vary between maximum 16-grams and maximum 32-grams configurations.\n
* Evaluation output for training different models (JSON format) is processed by `report.py`
to allow for comparison.\n
* GPU is used only for the transformer models.\n
* A `suggester` configuration for maximum 32-grams with a **transformer** model will run out
of 8GB memory of a GPU. In the provided configuration here batch sizes are tweaked to make it run,
but at a loss of some twenty percent of accuracy.
* On a 6-core CPU, a 32-grams configuration with a transformer model took some 14 hours to run!\n
\n
Python code is used to:\n
* create the corpus in `spacy` format from the original dataset.\n
* extract data from generated metrics files for reporting.\n
"

vars:
  config_sm: "config_sm"
  config_lg: "config_lg"
  config_trf: "config_trf"
  gpu: -1
  # Disable GPU by setting its values to -1
  gpu_trf_16: 0
  gpu_trf_32: 0
  spans_key: "mnp"

directories: ["assets", "training", "configs", "metrics", "corpus"]

assets:
  # We need only from ./data the files train_set_task2.txt, dev_set_task2.txt, and test_set_task2.txt
  # but downloading assets per file is broken, so we download all
  - dest: "assets"
    description: "Dev dataset from SemEval2021 Task-6 'Detection of Persuasive Techniques in Texts and Images'"
    git:
        repo: "https://github.com/di-dimitrov/SEMEVAL-2021-task6-corpus"
        branch: "main"
        path: "data"

workflows:
  all:
    - corpus
    - train_sm
    - train_lg
    - train_trf
    - report

commands:

  - name: corpus
    help: "Convert the data to spaCy's format"
    script:
      - "python scripts/make_corpus.py"
    deps:
      - "scripts/make_corpus.py"
      - "assets/dev_set_task2.txt"
      - "assets/training_set_task2.txt"
      - "assets/test_set_task2.txt"
    outputs:
      - "corpus/train.spacy"
      - "corpus/dev.spacy"
      - "corpus/eval.spacy"

  - name: train_sm
    help: "Train and evaluate 'sm' model for 16-grams and 32-grams configurations"
    script:
      # 16-grams
      - "python -m spacy train configs/${vars.config_sm}_16.cfg -o training/ \
        --gpu-id ${vars.gpu} \
        --paths.train corpus/train.spacy --paths.dev corpus/dev.spacy"
      - "python scripts/evaluate_token.py ./training/model-best ./corpus/eval.spacy \
        --output ./metrics/${vars.config_sm}_16.json --gpu-id ${vars.gpu} \
        --spans-key ${vars.spans_key}"
      - "rm -rf training"
      # 32-grams
      - "python -m spacy train configs/${vars.config_sm}_32.cfg -o training/ \
        --gpu-id ${vars.gpu} \
        --paths.train corpus/train.spacy --paths.dev corpus/dev.spacy"
      - "python scripts/evaluate_token.py ./training/model-best ./corpus/eval.spacy \
        --output ./metrics/${vars.config_sm}_32.json --gpu-id ${vars.gpu} \
        --spans-key ${vars.spans_key}"
      - "rm -rf training"
    deps:
      - "corpus/train.spacy"
      - "corpus/dev.spacy"
      - "configs/${vars.config_sm}_16.cfg"
      - "configs/${vars.config_sm}_32.cfg"
    outputs:
      - "metrics/${vars.config_sm}_16.json"
      - "metrics/${vars.config_sm}_32.json"

  - name: train_lg
    help: "Train and evaluate 'lg' model for 16-grams and 32-grams configurations"
    script:
      # 16-grams
      - "python -m spacy train configs/${vars.config_lg}_16.cfg -o training/ \
        --gpu-id ${vars.gpu} \
        --paths.train corpus/train.spacy --paths.dev corpus/dev.spacy"
      - "python scripts/evaluate_token.py ./training/model-best ./corpus/eval.spacy \
        --output ./metrics/${vars.config_lg}_16.json --gpu-id ${vars.gpu} \
        --spans-key ${vars.spans_key}"
      - "rm -rf training"
      # 32-grams
      - "python -m spacy train configs/${vars.config_lg}_32.cfg -o training/ \
        --gpu-id ${vars.gpu} \
        --paths.train corpus/train.spacy --paths.dev corpus/dev.spacy"
      - "python scripts/evaluate_token.py ./training/model-best ./corpus/eval.spacy \
        --output ./metrics/${vars.config_lg}_32.json --gpu-id ${vars.gpu} \
        --spans-key ${vars.spans_key}"
      - "rm -rf training"
    deps:
      - "corpus/train.spacy"
      - "corpus/dev.spacy"
      - "configs/${vars.config_lg}_16.cfg"
      - "configs/${vars.config_lg}_32.cfg"
    outputs:
      - "metrics/${vars.config_lg}_16.json"
      - "metrics/${vars.config_lg}_32.json"

  - name: train_trf
    help: "Train and evaluate 'trf' model for 16-grams and 32-grams configurations"
    script:
      # 16-grams
      - "python -m spacy train configs/${vars.config_trf}_16.cfg -o training/ \
        --gpu-id ${vars.gpu_trf_16} \
        --paths.train corpus/train.spacy --paths.dev corpus/dev.spacy"
      - "python scripts/evaluate_token.py ./training/model-best ./corpus/eval.spacy \
        --output ./metrics/${vars.config_trf}_16.json --gpu-id ${vars.gpu_trf_16} \
        --spans-key ${vars.spans_key}"
      - "rm -rf training"
      # 32-grams with configuration tweaked to train within 8GB GPU
      - "python -m spacy train configs/${vars.config_trf}_32_GPU.cfg -o training/ \
        --gpu-id ${vars.gpu_trf_32} \
        --paths.train corpus/train.spacy --paths.dev corpus/dev.spacy"
      # 32-grams with default configuration to run within CPU.
      #- "python -m spacy train configs/${vars.config_trf}_32.cfg -o training/ \
      #  --gpu-id -1 \
      #  --paths.train corpus/train.spacy --paths.dev corpus/dev.spacy"
      - "python scripts/evaluate_token.py ./training/model-best ./corpus/eval.spacy \
        --output ./metrics/${vars.config_trf}_32.json --gpu-id ${vars.gpu_trf_32} \
        --spans-key ${vars.spans_key}"
      - "rm -rf training"
    deps:
      - "corpus/train.spacy"
      - "corpus/dev.spacy"
      - "configs/${vars.config_trf}_16.cfg"
      - "configs/${vars.config_trf}_32_GPU.cfg"
    outputs:
      - "training/model-best"
      - "metrics/${vars.config_trf}_16.json"
      - "metrics/${vars.config_trf}_32.json"

  - name: report
    help: 'Convert metrics of the different trained models to CSV for reading into notebook'
    script:
      - 'python scripts/report.py --spans-key ${vars.spans_key} \
        --paths_input metrics --paths_output metrics'
    deps:
      - 'metrics/config_sm_16.json'
      - 'metrics/config_sm_32.json'
      - 'metrics/config_lg_16.json'
      - 'metrics/config_lg_32.json'
      - 'metrics/config_trf_16.json'
      - 'metrics/config_trf_32.json'
    outputs:
      - 'metrics/totals_16.csv'
      - 'metrics/per_label_16.csv'
      - 'metrics/totals_32.csv'
      - 'metrics/per_label_32.csv'

  - name: clean
    help: "Remove intermediate files"
    # NOTE: we can't write "rm -rf corpus/*" because spaCy wraps the argument in quotes,
    #       which prevents the wildcard '*' from expanding.
    #       Hence we delete the directories themselves
    script:
      - "rm -rf corpus"
      - "rm -rf training"
      - "rm -rf metrics"
      - "rm -rf packages"
